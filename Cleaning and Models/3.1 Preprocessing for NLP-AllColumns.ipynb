{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc2dcbea",
   "metadata": {},
   "source": [
    "# Processing data for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a1a33bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ba32e",
   "metadata": {},
   "source": [
    "### Defining functions: \n",
    "- Tokenize\n",
    "- Lemmatize\n",
    "- Stemmize\n",
    "- Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3b7280f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "\n",
    "    tokens = word_tokenize(s)\n",
    "    return tokens\n",
    "\n",
    "def stemmer_words(l):\n",
    "    sb = SnowballStemmer('portuguese')\n",
    "    stemmed = [sb.stem(word) for word in l] \n",
    "    \n",
    "    return stemmed\n",
    "\n",
    "def lemmatize(l):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in l]\n",
    "\n",
    "    return lemmatized\n",
    "\n",
    "def remove_stopwords(l):\n",
    "    stopwords.words('portuguese')\n",
    "    without_sw = [word for word in l if not word in stopwords.words()]\n",
    "    \" \".join(without_sw)\n",
    "\n",
    "    return without_sw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b7a723",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c3968525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>rating</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corinthians publicou nota de repúdio sobre a...</td>\n",
       "      <td>corinthians noto oficial repúdio o realização ...</td>\n",
       "      <td>entretenimento</td>\n",
       "      <td>2021-02</td>\n",
       "      <td>Edgard Matsuki</td>\n",
       "      <td>boatos.org</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>É falso que família de Ciro Gomes tenha 77 emp...</td>\n",
       "      <td>haver indício o família gomar participar negóc...</td>\n",
       "      <td>política</td>\n",
       "      <td>2020-07</td>\n",
       "      <td>Comprova</td>\n",
       "      <td>projetocomprova.com.br</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jul</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ex chefe da comunicação da PF volta ao posto a...</td>\n",
       "      <td>o delegar polícia federal fabio ricardo ciavol...</td>\n",
       "      <td>política</td>\n",
       "      <td>2020-05</td>\n",
       "      <td>FelipeNériG1</td>\n",
       "      <td>g1.globo.com</td>\n",
       "      <td>1.0</td>\n",
       "      <td>May</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0    Corinthians publicou nota de repúdio sobre a...   \n",
       "1  É falso que família de Ciro Gomes tenha 77 emp...   \n",
       "2  Ex chefe da comunicação da PF volta ao posto a...   \n",
       "\n",
       "                                                text             tag     date  \\\n",
       "0  corinthians noto oficial repúdio o realização ...  entretenimento  2021-02   \n",
       "1  haver indício o família gomar participar negóc...        política  2020-07   \n",
       "2  o delegar polícia federal fabio ricardo ciavol...        política  2020-05   \n",
       "\n",
       "           author                     url  rating month  year  \n",
       "0  Edgard Matsuki              boatos.org     0.0   Feb  2021  \n",
       "1        Comprova  projetocomprova.com.br     0.0   Jul  2020  \n",
       "2    FelipeNériG1            g1.globo.com     1.0   May  2020  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv('news.tsv').drop(\"Unnamed: 0\", axis = 1)\n",
    "news.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0306462",
   "metadata": {},
   "source": [
    "### Encoding tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4d269a",
   "metadata": {},
   "source": [
    "import sklearn.preprocessing as preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6beaf8a",
   "metadata": {},
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9a41a",
   "metadata": {},
   "source": [
    "news['tagenc']=le.fit_transform(news.tag.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8e6a43",
   "metadata": {},
   "source": [
    "tags=pd.DataFrame(pd.get_dummies(news.rating)[0.0])\n",
    "tags['tagenc']=news['tagenc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a534f",
   "metadata": {},
   "source": [
    "tags.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9b771f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "news2 = news.drop(columns=['month', 'year','rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "62d00dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(s):\n",
    "    s.lower()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b013a75d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9040/2728033038.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnews2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mnews2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnews2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9040/4194325390.py\u001b[0m in \u001b[0;36mlower\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "for column in news2.columns:\n",
    "    news2[column] = news2[column].apply(lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9054a",
   "metadata": {},
   "source": [
    "### Applying functions to all text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a187761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in news2.columns:\n",
    "    news2[column] = news2[column].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0480b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in news2.columns:\n",
    "    news2[column] = news2[column].apply(stemmer_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "434c96d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's apply this to the all the newsfeed \n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# unfortunately pos_tag and lemmatize use different codes for parts of speech \n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper() # gets first letter of POS categorization\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN) # get returns second argument if first key does not exist #default value if its not of the possibilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ad9607d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in news2.columns:\n",
    "    news2[column] = news2[column].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48239dbd",
   "metadata": {},
   "source": [
    "#Wait for now, too slow to run\n",
    "for column in news2.columns:\n",
    "    news2[column] = news2[column].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095716d2",
   "metadata": {},
   "source": [
    "## Creating a different set for validation and train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e794f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news2['rating'] = news['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2b4d476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#news2['tag'] = news['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eb41fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving a sample for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c636b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove month and year again - leave only date\n",
    "#news.drop(columns = ['month', 'year'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d5449ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11911, 7)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "dbea8315",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_news = news2.loc[0:999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "85915ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 7)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f20b013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_news.to_csv(\"val_news2.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f4b6aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsu2 = news2.loc[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6b4d188a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title     0\n",
       "text      0\n",
       "tag       0\n",
       "date      0\n",
       "author    0\n",
       "url       0\n",
       "rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsu2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c8624a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newsu2['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ca443820",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsu2.to_csv(\"newsu2.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "67332fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>url</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>[weintraub, diz, que, alun, inscrit, decid, da...</td>\n",
       "      <td>[hor, anunc, pesquis, alun, inscrit, enem, opi...</td>\n",
       "      <td>[saúd]</td>\n",
       "      <td>[2020-05]</td>\n",
       "      <td>[educaca]</td>\n",
       "      <td>[educacao.uol.com.br]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>[segund, do, da, coronavac, nã, está, relacion...</td>\n",
       "      <td>[do, escalon, comum, program, vacin, e, serv, ...</td>\n",
       "      <td>[saúd]</td>\n",
       "      <td>[2021-01]</td>\n",
       "      <td>[comprov]</td>\n",
       "      <td>[projetocomprova.com.br]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>[prisã, na, cpi, é, suc, de, brasil, onde, a, ...</td>\n",
       "      <td>[o, ex, diretor, logíst, ministéri, saud, robe...</td>\n",
       "      <td>[brasil]</td>\n",
       "      <td>[2021-07]</td>\n",
       "      <td>[notic]</td>\n",
       "      <td>[noticias.uol.com.br]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[alvo, da, justic, ex, govern, ricard, coutinh...</td>\n",
       "      <td>[acus, particip, esquem, desvi, dinheir, públi...</td>\n",
       "      <td>[polít]</td>\n",
       "      <td>[2020-09]</td>\n",
       "      <td>[raniery, soaresespecialp, estad]</td>\n",
       "      <td>[noticias.uol.com.br]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>[o, pap, francisc, hologram]</td>\n",
       "      <td>[o, víd, surg, o, red, social, o, seman, abril...</td>\n",
       "      <td>[entreten]</td>\n",
       "      <td>[2020-04]</td>\n",
       "      <td>[gilmarlop]</td>\n",
       "      <td>[e-farsas.com]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11906</th>\n",
       "      <td>[deolan, bezerr, espos, de, mc, kevin, é, advo...</td>\n",
       "      <td>[o, advog, deolan, bezerr, fich, visit, pres, ...</td>\n",
       "      <td>[entreten]</td>\n",
       "      <td>[2021-05]</td>\n",
       "      <td>[raian, gonol]</td>\n",
       "      <td>[boatos.org]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11907</th>\n",
       "      <td>[corregedor, da, pgr, abre, sindic, par, apur,...</td>\n",
       "      <td>[o, corregedor, geral, ministéri, públic, fede...</td>\n",
       "      <td>[brasil]</td>\n",
       "      <td>[2022-05]</td>\n",
       "      <td>[aguirr, talent]</td>\n",
       "      <td>[extra.globo.com]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11908</th>\n",
       "      <td>[após, se, aproxim, de, bolsonar, govern, do, ...</td>\n",
       "      <td>[o, govern, distrit, federal, iban, roch, mdb,...</td>\n",
       "      <td>[saúd]</td>\n",
       "      <td>[2020-04]</td>\n",
       "      <td>[jul, lindner, mateus]</td>\n",
       "      <td>[noticias.uol.com.br]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11909</th>\n",
       "      <td>[quand, o, crim, só, vem, no, fim, ou, atir, f...</td>\n",
       "      <td>[artig, o, livr, suspeiçã, merec, leitur, aten...</td>\n",
       "      <td>[polít]</td>\n",
       "      <td>[2020-03]</td>\n",
       "      <td>[notic]</td>\n",
       "      <td>[noticias.uol.com.br]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11910</th>\n",
       "      <td>[itál, aind, nã, ating, pic, de, contági, por,...</td>\n",
       "      <td>[o, diretor, institut, nacional, saud, itál, s...</td>\n",
       "      <td>[saúd]</td>\n",
       "      <td>[2020-03]</td>\n",
       "      <td>[notic]</td>\n",
       "      <td>[noticias.uol.com.br]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10911 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "1000   [weintraub, diz, que, alun, inscrit, decid, da...   \n",
       "1001   [segund, do, da, coronavac, nã, está, relacion...   \n",
       "1002   [prisã, na, cpi, é, suc, de, brasil, onde, a, ...   \n",
       "1003   [alvo, da, justic, ex, govern, ricard, coutinh...   \n",
       "1004                        [o, pap, francisc, hologram]   \n",
       "...                                                  ...   \n",
       "11906  [deolan, bezerr, espos, de, mc, kevin, é, advo...   \n",
       "11907  [corregedor, da, pgr, abre, sindic, par, apur,...   \n",
       "11908  [após, se, aproxim, de, bolsonar, govern, do, ...   \n",
       "11909  [quand, o, crim, só, vem, no, fim, ou, atir, f...   \n",
       "11910  [itál, aind, nã, ating, pic, de, contági, por,...   \n",
       "\n",
       "                                                    text         tag  \\\n",
       "1000   [hor, anunc, pesquis, alun, inscrit, enem, opi...      [saúd]   \n",
       "1001   [do, escalon, comum, program, vacin, e, serv, ...      [saúd]   \n",
       "1002   [o, ex, diretor, logíst, ministéri, saud, robe...    [brasil]   \n",
       "1003   [acus, particip, esquem, desvi, dinheir, públi...     [polít]   \n",
       "1004   [o, víd, surg, o, red, social, o, seman, abril...  [entreten]   \n",
       "...                                                  ...         ...   \n",
       "11906  [o, advog, deolan, bezerr, fich, visit, pres, ...  [entreten]   \n",
       "11907  [o, corregedor, geral, ministéri, públic, fede...    [brasil]   \n",
       "11908  [o, govern, distrit, federal, iban, roch, mdb,...      [saúd]   \n",
       "11909  [artig, o, livr, suspeiçã, merec, leitur, aten...     [polít]   \n",
       "11910  [o, diretor, institut, nacional, saud, itál, s...      [saúd]   \n",
       "\n",
       "            date                             author                       url  \\\n",
       "1000   [2020-05]                          [educaca]     [educacao.uol.com.br]   \n",
       "1001   [2021-01]                          [comprov]  [projetocomprova.com.br]   \n",
       "1002   [2021-07]                            [notic]     [noticias.uol.com.br]   \n",
       "1003   [2020-09]  [raniery, soaresespecialp, estad]     [noticias.uol.com.br]   \n",
       "1004   [2020-04]                        [gilmarlop]            [e-farsas.com]   \n",
       "...          ...                                ...                       ...   \n",
       "11906  [2021-05]                     [raian, gonol]              [boatos.org]   \n",
       "11907  [2022-05]                   [aguirr, talent]         [extra.globo.com]   \n",
       "11908  [2020-04]             [jul, lindner, mateus]     [noticias.uol.com.br]   \n",
       "11909  [2020-03]                            [notic]     [noticias.uol.com.br]   \n",
       "11910  [2020-03]                            [notic]     [noticias.uol.com.br]   \n",
       "\n",
       "       rating  \n",
       "1000      1.0  \n",
       "1001      0.0  \n",
       "1002      0.0  \n",
       "1003      1.0  \n",
       "1004      0.0  \n",
       "...       ...  \n",
       "11906     0.0  \n",
       "11907     1.0  \n",
       "11908     1.0  \n",
       "11909     1.0  \n",
       "11910     1.0  \n",
       "\n",
       "[10911 rows x 7 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b12b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
